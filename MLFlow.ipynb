{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVyVPFA6yXBW+Yp1vJe2Hn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/negocia438/OC_P7/blob/main/MLFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-DAQLz1XeUWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Projet 7 - Implémentez un modèle de scoring\n",
        "\n",
        "\n",
        "##Contexte\n",
        "\n",
        "Entreprise: \"Pret à dépenser\" qui Propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt\n",
        "\n",
        "### 1. Création d'un “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé\n",
        "\n",
        "\n",
        "\n",
        "Importance de la transparance (souhait des clients + valeurs de l'entreprise)\n",
        "Dashboard interactif: Pour pouvoir expliquer de façon la plus transparente possible les décisions d’octroi de crédit\n",
        "Permet aussi à leurs clients de disposer de leurs informations personnelles et de les explorer facilement\n",
        "\n",
        "### 2. Construire un modèle de scoring qui donnera une prédiction (classification) sur la probabilité de faillite d'un client de façon automatique\n",
        "Construire un dashboard interactif permettant d'interpréter les prédictions faites par le modèle, et d’améliorer la connaissance client\n",
        "\n",
        "### 3. Mettre en production le modèle de scoring de prédiction à l’aide d’une API, ainsi que le dashboard interactif qui appelle l’API pour les prédictions\n",
        "Utiliser des kernels Kaggle (optionel) pour faciliter l’analyse exploratoire, la préparation des données et le feature engineering nécessaires à l’élaboration du modèle de scoring\n",
        "\n",
        "Spécifications du dashbord\n",
        "\n",
        "Visualiser le score et l’interprétation de ce score pour chaque client de façon clair et simple\n",
        "Visualiser des informations descriptives relatives à un client (via un système de filtre)\n",
        "Comparer les informations descriptives d'un client à un groupe de clients similaires\n",
        "Partie technique\n",
        "Dahboard interactif: Dash OU Bokeh OU Streamlit\n",
        "\n",
        "Elaborer une plateforme MLOps: https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P7/Outils+Open+Source+MLOps.pdf\n",
        "\n",
        "\n",
        "Librairie evidently pour détecter du Data Drift en production\n",
        "\n",
        "Hypothèse: “application_train” = datas pour la modélisation ET “application_test” = datas de nouveaux clients\n",
        "Créer un tableau HTML pour illustrer ce data drift\n",
        "Déploiement de l'application dashboard et de l’API: Plateforme Cloud (gratuit), plusieurs choix s'offrent à nous:\n",
        "\n",
        "Azure webapp (ASP F1 gratuit)\n",
        "PythonAnywhere\n",
        "Heroku avec le package “student” de Github\n",
        "Effectuer de la Cross-Validation\n",
        "\n",
        "Si les scores scores AUC sont supérieurs à 0.82, le modèle possède probablement de l’overfitting\n",
        "\n",
        "Création d'une note technique: Présentera l’élaboration du modèle jusqu’à l’analyse du Data Drift\n",
        "\n",
        "Conseils sur l'elaboration du modèle\n",
        "Prendre en compte le déséquilibre entre le nombre de bons et de moins bons clients (utiliser une méthode au choix)\n",
        "\n",
        "Prendre en compte le déséquilibre du coût métier entre entre un faux négatif et un faux positif:\n",
        "\n",
        "Faux négatif: mauvais client prédit bon client : donc crédit accordé et perte en capital\n",
        "Faux positif: Bon client prédit mauvais : donc refus crédit et manque à gagner en marge\n",
        "Hypothèse: le coût d’un FN est dix fois supérieur au coût d’un FP\n",
        "Création d'un score \"métier\": Minimisation du coût d’erreur de prédiction des FN et FP\n",
        "\n",
        "Ce score permet de choisir le meilleur modèle et ses meilleurs hyperparamètres\n",
        "Attention: Minimisation score métier -> optimisation du seuil qui détermine, la classe 0 ou 1\n",
        "Un “predict” suppose un seuil à 0.5 qui n’est pas forcément l’optimum\n",
        "Utiliser aussi l'ACU et l'accuracy pour affiner notre modèle et ses hyperparamètres\n",
        "\n",
        "Livrable\n",
        "Application de dashboard interactif + l’API de prédiction du score, déployées chacunes sur le cloud.\n",
        "Un dossier, géré via un outil de versioning de code contenant:\n",
        "Notebook de la modélisation (du prétraitement à la prédiction), intégrant via MLFlow le tracking d’expérimentations et le stockage centralisé des modèles\n",
        "Le code générant le dashboard\n",
        "Le code permettant de déployer le modèle sous forme d'API\n",
        "Un fichier permettant de comprendre l'objectif du projet et le découpage des dossiers\n",
        "Un fichier listant les packages utilisés\n",
        "Tableau HTML d’analyse de data drift réalisé à partir d’evidently\n",
        "Une note méthodologique (PDF?) décrivant:\n",
        "La méthodologie d'entraînement du modèle (2 pages maximum)\n",
        "Le traitement du déséquilibre des classes (1 page maximum)\n",
        "La fonction coût métier, l'algorithme d'optimisation et la métrique d'évaluation (1 page maximum)\n",
        "Un tableau de synthèse des résultats (1 page maximum)\n",
        "L’interprétabilité globale et locale du modèle (1 page maximum)\n",
        "Les limites et les améliorations possibles (1 page maximum)\n",
        "L’analyse du Data Drift (1 page maximum)\n",
        "Un support de présentation pour la soutenance (Powerpoint)\n",
        "Copies écran des commits, du dossier Github (+ lien vers ce dossier) et de l’exécution des tests unitaires\n",
        "Ce sont les preuves qu’un pipeline de déploiement continu a permis de déployer l’API, doivent être formalisés dans ce support de présentation\n"
      ],
      "metadata": {
        "id": "1AkVqEyoeWJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvi9MXBEfVnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}